{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"5c25cb0a84a14031ba28521f128e802e","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["Numeric features"]},{"cell_type":"code","execution_count":null,"metadata":{"allow_embed":"code","cell_id":"49df8dada1d94402802487955da167a8","deepnote_cell_height":581.390625,"deepnote_cell_type":"code","deepnote_output_heights":[39.390625],"deepnote_to_be_reexecuted":false,"execution_millis":11,"execution_start":1661529899105,"source_hash":"d3f7ee6f","tags":[]},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# scaling\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","X_standard = StandardScaler().fit_transform(X)\n","X_minmax = MinMaxScaler().fit_transform(X)\n","\n","# Winsorization for outliers\n","UB, LB = np.percentile(X, [1, 99]) # 1st and 99th percentile\n","y = np.clip(X, UB, LB)\n","\n","# rank transfomration\n","from scipy.stats import rankdata\n","rankdata([-100, 0, 1e5]) # [1., 2., 3.]\n"," \n","# log transform\n","np.log(1 + X)\n","\n","# raising to power\n","np.sqrt(X + 2/3)\n","np.power(X + 2/3, 1/2) # same as above\n","\n","# feature generation\n","df['unit_price'] = df['price'] / df['area']\n","df['decimal'] = (np.modf(df['dollars'])[0] * 100).astype(int)"]},{"cell_type":"markdown","metadata":{"cell_id":"b7ab6dbe936e48e6a20c2f36e6a79d2d","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["categorical and ordinal features"]},{"cell_type":"code","execution_count":null,"metadata":{"allow_embed":"code","cell_id":"70f98148fc8e4e9182c0cd9fd5968849","deepnote_cell_height":427.1875,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1896,"execution_start":1661642880236,"source_hash":"12379d13","tags":[]},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","## label encoding\n","lab = LabelEncoder()\n","df['column'] = lab.fit_transform(df['column'])\n","\n","\n","## frequency encoding\n","encoding = (df.groupby('column').size()) / len(train)\n","df['encoding'] = df['column'].apply(lambda x : encoding[x])\n","\n","\n","## one-hot encoding\n","df = pd.get_dummies(df, columns = ['col1', 'col2'])\n","\n","## feature generation\n","df['col1_col2'] = df['col1'] + df['col2']"]},{"cell_type":"markdown","metadata":{"cell_id":"98366834b30e4a50bdf1782a89c17759","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["datetime and coordinates"]},{"cell_type":"code","execution_count":null,"metadata":{"allow_embed":true,"cell_id":"9b22ddfd895a408ea8dc90a3df45732e","deepnote_cell_height":583,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":["# pip install holidays\n","import holidays\n","import datetime\n","us_holidays = holidays.US()\n","\n","# ex: 2016-01-02 01:00:00\n","df['weekday'] = df.Date.dt.weekday\n","df['year'] = df.Date.dt.year\n","df['quarter'] = df.Date.dt.quarter\n","df['weekofyear'] = df.Date.dt.weekofyear\n","df['dayofweek'] = df.Date.dt.dayofweek\n","df['dayofweek_name'] = df.Date.dt.weekday_name\n","df['month'] = df.Date.dt.month\n","df['day'] = df.Date.dt.day\n","df['hour'] = df.Date.dt.hour\n","df['second'] = df.Date.dt.second\n","df['minute'] = df.Date.dt.minute\n","\n","df[\"is_holiday\"] = df.Date.dt.floor('d').isin(us_holidays)\n","df['is_weekend'] = np.where(df['dayofweek_name'].isin(['Sunday','Saturday']), 1, 0)\n","\n","# time since today\n","df['time_since'] = datetime.datetime.today() - df.Date\n","\n","# difference bewteen two dates\n","df['diff_time'] = (df['date_1'] - df['date_2'])\n","df['diff_days'] = (df['date_1'] - df['date_2']) / np.timedelta64(1, 'D')\n","df['diff_weeks'] = (df['date_1'] - df['date_2']) / np.timedelta64(1, 'W')\n","df['diff_months'] = (df['date_1'] - df['date_2']) / np.timedelta64(1, 'M')\n","df['diff_years'] = (df['date_1'] - df['date_2']) / np.timedelta64(1, 'Y')"]},{"cell_type":"markdown","metadata":{"cell_id":"f998aab0ba374935b84e7b7b34784569","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["missing values"]},{"cell_type":"code","execution_count":null,"metadata":{"allow_embed":"code","cell_id":"b6fec794f7fe4ae1ae0256bc3ee0ffcf","deepnote_cell_height":331,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":["import numpy as np\n","\n","# replace with nan\n","df.replace({\"-\":np.nan, \"?\":np.nan}, inplace=True)\n","\n","# replace with -999\n","df[\"column\"].fillna(-999, inplace = True)\n","\n","# replace with mean/median\n","df[\"age\"].fillna(df[\"age\"].mean(), inplace=True)\n","df[\"age\"].fillna(df[\"age\"].median(), inplace=True)\n","\n","# other methods\n","df.fillna(method ='pad') # forward fill\n","df.fillna(method ='bfill') # backward fill\n","df.interpolate(method ='linear') # linear interpolation"]},{"cell_type":"markdown","metadata":{"cell_id":"888e2b79381040c588171e32d53112ee","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["Text data"]},{"cell_type":"code","execution_count":null,"metadata":{"allow_embed":"code","cell_id":"1edf6735460c44a9b3850e6924127547","deepnote_cell_height":673,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n","\n","# bag of words\n","# Transforms text into a sparse matrix of n-gram counts.\n","vect = CountVectorizer()\n","word_counts = vect.fit_transform(corpus)\n","\n","# tfidf\n","# Transform a count matrix to a normalized tf or tf-idf representation.\n","transformer = TfidfTransformer(smooth_idf=False)\n","tfidf = transformer.fit_transform(word_counts)\n","tfidf\n","\n","# BOW + TFIDF\n","# Convert a collection of raw documents to a matrix of TF-IDF features\n","vect = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","\n","# ngrams\n","from nltk import ngrams\n","sentence = \"this is a sentence\"\n","bigrams = ngrams(sentence.split(), 2)\n","trigrams = ngrams(sentence.split(), 3)\n","\n","# word2vec\n","import gensim\n","from gensim.models import Word2Vec\n","\n","# CBOW approach by default\n","model = gensim.models.Word2Vec(corpus, min_count = 1,\n","                              vector_size = 100, window = 5, sg=0)\n","\n","# skipgram\n","model = gensim.models.Word2Vec(corpus, min_count = 1,\n","                              vector_size = 100, window = 5, sg=1)"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c38ba0b2d7e6465c851731ba9a341beb","deepnote_persisted_session":{"createdAt":"2022-08-28T00:01:18.588Z","filename":"session_dump_c8a16df5-4f6a-415c-85c9-89e0b07cef5f.pkl"},"kernelspec":{"display_name":"Python 3.10.0 64-bit ('3.10.0')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"50587d438b9934cf2712ee500622f7def3550698a6c70c07f7d3c00dd27cb653"}}},"nbformat":4,"nbformat_minor":0}
